{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ovsv12Rhro43"
      },
      "outputs": [],
      "source": [
        "# Connect to  Google Driver\n",
        "# 1. Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6CtNwgRX5py"
      },
      "source": [
        "# IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jL6ku0irr4tR"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import gensim\n",
        "import numpy as np\n",
        "from pandas import DataFrame\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from matplotlib.ticker import PercentFormatter\n",
        "\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "from tensorflow.keras.preprocessing import text, sequence\n",
        "from tensorflow.keras.layers import Layer, InputLayer, Input\n",
        "from tensorflow.keras.layers import Dense, Input, LSTM, Bidirectional, Conv1D, Add, Concatenate\n",
        "from tensorflow.keras.layers import Dropout, Embedding, BatchNormalization, Flatten, Reshape\n",
        "from tensorflow.keras.layers import Attention, GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, SpatialDropout1D, MaxPool1D, MaxPooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7PrzPigsBWf"
      },
      "source": [
        "# READ DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o0Z2HwW_vYuc"
      },
      "outputs": [],
      "source": [
        "X_train = np.load('/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Clean Data/X_train.npy', allow_pickle=True)\n",
        "y_train = np.load('/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Clean Data/y_train.npy', allow_pickle=True)\n",
        "X_valid = np.load('/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Clean Data/X_valid.npy', allow_pickle=True )\n",
        "y_valid = np.load('/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Clean Data/y_valid.npy', allow_pickle=True)\n",
        "X_test = np.load('/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Clean Data/X_test.npy', allow_pickle=True )\n",
        "y_test = np.load('/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Clean Data/y_test.npy', allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8InlXU0ysqFh"
      },
      "outputs": [],
      "source": [
        "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Kbp_XPzUyYrn"
      },
      "outputs": [],
      "source": [
        "y_train = pd.DataFrame(y_train, columns = ['Sentiment'])\n",
        "y_test = pd.DataFrame(y_test, columns = ['Sentiment'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "454EcVfYszOm"
      },
      "source": [
        "# TOKENIZERATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mxOEL-s2swNL"
      },
      "outputs": [],
      "source": [
        "max_length = 128\n",
        "embedding_dim = 300\n",
        "\n",
        "# Vectorize text + Prepare  Embedding\n",
        "tokenizer = text.Tokenizer(oov_token='<OOV>', lower=True)\n",
        "tokenizer.fit_on_texts(list(X_train))\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_valid = tokenizer.texts_to_sequences(X_valid)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_length)\n",
        "X_valid = sequence.pad_sequences(X_valid, maxlen=max_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWXVEL5Ts3y9"
      },
      "source": [
        "# GET THE EMBEDDING MATRIX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Lj0Zj-Brs57B"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_FILE = r'/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Embedding/GoogleNews-vectors-negative300.bin'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = tokenizer.word_index"
      ],
      "metadata": {
        "id": "fchB-9z_mcqh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCjAO6_EtT72"
      },
      "outputs": [],
      "source": [
        "# load google news vectors\n",
        "embedding_index = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_bbk5kQtpE3",
        "outputId": "cc703027-e0dd-4874-e047-e5f1d1b1e272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48680, 48680)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "num_words = vocab_size\n",
        "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
        "\n",
        "num_words, vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I67Hh7PATIw0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RENTvLRavZNP"
      },
      "outputs": [],
      "source": [
        "for word, i in word_index.items():\n",
        "  if i >= vocab_size:\n",
        "    continue\n",
        "  try:\n",
        "    embedding_vector = embedding_index.get_vector(word)\n",
        "\n",
        "    if embedding_vector is not None:\n",
        "      embedding_matrix[i] = embedding_vector\n",
        "\n",
        "  except (KeyError):\n",
        "    continue"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_matrix = np.load('/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Embedding/embedding_matrix_corona_tweet_oov.npy', allow_pickle = True)"
      ],
      "metadata": {
        "id": "dwIChN4UmfpU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "tqfd5IXtxPx7"
      },
      "outputs": [],
      "source": [
        "#  load pre-trained word embeddings into an Embedding layer\n",
        "embedding_layer_google = Embedding(num_words,\n",
        "                                   embedding_dim,\n",
        "                                   embeddings_initializer=Constant(embedding_matrix),\n",
        "                                   input_length=max_length,\n",
        "                                   trainable=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IHtoW5eB-lVi"
      },
      "source": [
        "#ATTENTION LAYER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6RECN_E_uek1"
      },
      "outputs": [],
      "source": [
        "class attention(Layer):\n",
        "    def __init__(self, return_sequences=True):\n",
        "        self.return_sequences = return_sequences\n",
        "\n",
        "        super(attention,self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W=self.add_weight(name=\"att_weight\", \n",
        "                               shape=(input_shape[-1],1),\n",
        "                               initializer=\"normal\")\n",
        "        \n",
        "        self.b=self.add_weight(name=\"att_bias\", \n",
        "                               shape=(input_shape[1],1),\n",
        "                               initializer=\"normal\")\n",
        "        \n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1))\n",
        "\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1))\n",
        "\n",
        "        super(attention, self).build(input_shape)\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
        "        a = K.softmax(e, axis=1)\n",
        "        output = x*a\n",
        "        if self.return_sequences:\n",
        "\n",
        "            return output\n",
        "        return K.sum(output, axis=1)\n",
        "\n",
        "\n",
        "    def get_config(self):\n",
        "      return super(attention,self).get_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkMYjaKIuicG"
      },
      "source": [
        "# BUILD MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTwYpbQAzuH6"
      },
      "source": [
        "## CNN -> LSTM ->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV4K55vUuj0O"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1234)\n",
        "\n",
        "def create_CNN_LSTM_sequence(max_length=128, num_filters=128, kernel_size=5, LSTM_units=128, num_classes=3):\n",
        "  optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "  inp = Input(shape=(max_length,))\n",
        "\n",
        "  x = (embedding_layer_google)(inp)\n",
        "\n",
        "  x = Conv1D(filters=num_filters, \n",
        "            kernel_size=kernel_size, \n",
        "            strides=1 , \n",
        "            padding='same', \n",
        "            activation='relu', \n",
        "            kernel_initializer='he_uniform')(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = MaxPool1D(2)(x)\n",
        "\n",
        "  x = LSTM(units = LSTM_units, \n",
        "          return_sequences=True, \n",
        "          dropout=0.1, \n",
        "          recurrent_dropout=0.1, \n",
        "          activation='relu', \n",
        "          kernel_initializer='he_uniform')(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = attention(return_sequences=False)(x)\n",
        "\n",
        "  out = Dense(units=num_classes, activation='softmax', kernel_initializer='he_uniform')(x)\n",
        "\n",
        "  CNN_LSTM_sequence_model = Model(inp, out)\n",
        "  CNN_LSTM_sequence_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return CNN_LSTM_sequence_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsmjxBJn3BWr"
      },
      "outputs": [],
      "source": [
        "CNN_LSTM_sequence_model = create_CNN_LSTM_sequence()\n",
        "CNN_LSTM_sequence_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRfOwPws3k3-"
      },
      "outputs": [],
      "source": [
        "CNN_LSTM_sequence_model_checkpoint_path = \"/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Saved models/CNN_LSTM_sequence/temp/CNN_LSTM_sequence_model_checkpoint.ckpt\"\n",
        "CNN_LSTM_sequence_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                                                                filepath=CNN_LSTM_sequence_model_checkpoint_path,\n",
        "                                                                                verbose=1,\n",
        "                                                                                save_weights_only=True,\n",
        "                                                                                monitor='val_accuracy',\n",
        "                                                                                mode='max',\n",
        "                                                                                save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN_LSTM_sequence_model.load_weights(CNN_LSTM_sequence_model_checkpoint_path)"
      ],
      "metadata": {
        "id": "Bz8_AVKJpkxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1XqWtbTQ3k1W"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "hist_CNN_LSTM_sequence_model = CNN_LSTM_sequence_model.fit(x = X_train, y = y_train, \n",
        "                 batch_size = batch_size,\n",
        "                 epochs = epochs, \n",
        "                 validation_data = (X_valid, y_valid),\n",
        "                 verbose = 1,\n",
        "                 callbacks = [CNN_LSTM_sequence_model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3M0rN8VgEQbJ"
      },
      "outputs": [],
      "source": [
        "y_pred = CNN_LSTM_sequence_model.predict([X_test])\n",
        "y_pred_label = np.argmax(y_pred, axis=1)\n",
        "y_test_label = y_test\n",
        "\n",
        "class_name = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
        "print(classification_report(y_test_label, y_pred_label, target_names = class_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F148tYFXAC6G"
      },
      "source": [
        "##LSTM -> CNN ->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kreG6OTAH89"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(1234)\n",
        "\n",
        "def create_LSTM_CNN_sequence(max_length=128, num_filters=64, kernel_size=5, LSTM_units=128, num_classes=3):\n",
        "  optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "  inp = Input(shape=(max_length,))\n",
        "\n",
        "  x = (embedding_layer_google)(inp)\n",
        "\n",
        "  x = LSTM(units = LSTM_units, \n",
        "        return_sequences=True, \n",
        "        dropout=0.1, \n",
        "        recurrent_dropout=0.1, \n",
        "        activation='relu', \n",
        "        kernel_initializer='he_uniform')(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = attention(return_sequences=True)(x)\n",
        "\n",
        "  x = Conv1D(filters=num_filters, \n",
        "          kernel_size=kernel_size, \n",
        "          strides=1 , \n",
        "          padding='same', \n",
        "          activation='relu', \n",
        "          kernel_initializer='he_uniform')(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Dropout(0.2)(x)\n",
        "  x = GlobalMaxPooling1D()(x)\n",
        "\n",
        "\n",
        "\n",
        "  out = Dense(units=num_classes, activation='softmax', kernel_initializer='he_uniform')(x)\n",
        "\n",
        "  LSTM_CNN_sequence_model = Model(inp, out)\n",
        "  LSTM_CNN_sequence_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "  return LSTM_CNN_sequence_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW6kfD6OGDOe"
      },
      "outputs": [],
      "source": [
        "LSTM_CNN_sequence_model = create_LSTM_CNN_sequence()\n",
        "LSTM_CNN_sequence_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llx_TsBDGs4j"
      },
      "outputs": [],
      "source": [
        "LSTM_CNN_sequence_model_checkpoint_path = \"/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Saved models/LSTM_CNN_sequence/temp/LSTM_CNN_sequence_model_checkpoint.ckpt\"\n",
        "LSTM_CNN_sequence_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "                                                                                filepath=LSTM_CNN_sequence_model_checkpoint_path,\n",
        "                                                                                verbose=1,\n",
        "                                                                                save_weights_only=True,\n",
        "                                                                                monitor='val_accuracy',\n",
        "                                                                                mode='max',\n",
        "                                                                                save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM_CNN_sequence_model.load_weights(LSTM_CNN_sequence_model_checkpoint_path)"
      ],
      "metadata": {
        "id": "RVrTzObiNzAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PjAismw1Gs_I"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "hist_LSTM_CNN_sequence_model = LSTM_CNN_sequence_model.fit(x = X_train, y = y_train, \n",
        "                 batch_size = batch_size,\n",
        "                 epochs = epochs, \n",
        "                 validation_data = (X_valid, y_valid),\n",
        "                 verbose = 1,\n",
        "                 callbacks = [LSTM_CNN_sequence_model_checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.keras.models.save_model(LSTM_CNN_sequence_model, '/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Saved models/LSTM_CNN_sequence/LSTM_CNN_sequence_model')"
      ],
      "metadata": {
        "id": "teXeS-xUrYt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = LSTM_CNN_sequence_model.predict([X_test])\n",
        "y_pred_label = np.argmax(y_pred, axis=1)\n",
        "y_test_label = y_test\n",
        "\n",
        "class_name = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
        "print(classification_report(y_test_label, y_pred_label, target_names = class_name))"
      ],
      "metadata": {
        "id": "YkGE9zoSnZP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "e9-tU52sz0z4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01b74b23-0f09-4448-e90b-23d0e509898b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        }
      ],
      "source": [
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "inp = Input(shape=(max_length,))\n",
        "\n",
        "x = (embedding_layer_google)(inp)\n",
        "\n",
        "x1 = Conv1D(filters=128, \n",
        "           kernel_size=5, \n",
        "           strides=1 , \n",
        "           padding='same', \n",
        "           activation='relu', \n",
        "           kernel_initializer='he_uniform')(x)\n",
        "prev = x1\n",
        "\n",
        "x1 = Dropout(0.2)(x1)\n",
        "\n",
        "x1 = MaxPool1D(2)(x1)\n",
        "\n",
        "x1 = BatchNormalization()(x1)\n",
        "\n",
        "x1 = Flatten()(x1)\n",
        "\n",
        "out1 = Dense(3, activation='relu', kernel_initializer='he_uniform')(x1)\n",
        "\n",
        "out1 = Dropout(0.2)(out1)\n",
        "\n",
        "#######################################################\n",
        "\n",
        "x2 = LSTM(128, \n",
        "         return_sequences=True, \n",
        "         dropout=0.2, \n",
        "         recurrent_dropout=0.2, \n",
        "         activation='relu', \n",
        "         kernel_initializer='he_uniform')(x)\n",
        "x2 = Add()([prev, x2])\n",
        "x2 = Dropout(0.2)(x2)\n",
        "\n",
        "x2 = BatchNormalization()(x2)\n",
        "\n",
        "x2 = attention(return_sequences=False)(x2)\n",
        "\n",
        "out2 = Dense(3, activation='relu', kernel_initializer='he_uniform')(x2)\n",
        "\n",
        "out2 = Dropout(0.2)(out2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxhM-aWe0ByS"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "6Zizw8JCDbLj"
      },
      "outputs": [],
      "source": [
        "out11 = Dense(units = 3, activation = 'softmax', kernel_initializer = 'glorot_uniform')(out1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-uOsbKf0Dv0"
      },
      "source": [
        "##LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "V6vJ6V8t8USS"
      },
      "outputs": [],
      "source": [
        "out22 = Dense(3, activation='softmax', kernel_initializer='glorot_uniform')(out2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX06kqbS6Fot"
      },
      "outputs": [],
      "source": [
        "CNN_model = Model(inputs=inp, outputs=out11)\n",
        "CNN_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hAyafWh66vB_"
      },
      "outputs": [],
      "source": [
        "CNN_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "CNN_model_checkpoint_path = \"/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Saved models/CNN/temp/CNN_model_checkpoint.ckpt\"\n",
        "CNN_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=CNN_model_checkpoint_path,\n",
        "                                                                                verbose=1,\n",
        "                                                                                save_weights_only=True,\n",
        "                                                                                monitor='val_accuracy',\n",
        "                                                                                mode='max',\n",
        "                                                                                save_best_only=True)\n",
        "log_dir = \"logs/fit/\"\n",
        "CNN_model_tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "\n",
        "batch_size = 64\n",
        "epochs = 40"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN_model.load_weights(CNN_model_checkpoint_path)"
      ],
      "metadata": {
        "id": "DeJbMYLa-XSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fLYkOpCo6zoy"
      },
      "outputs": [],
      "source": [
        "CNN_hist = CNN_model.fit(x = X_train, y = y_train, \n",
        "                 batch_size = batch_size,\n",
        "                 epochs = epochs, \n",
        "                 validation_data = (X_valid, y_valid),\n",
        "                 verbose = 1,\n",
        "                 callbacks = [CNN_model_checkpoint_callback, CNN_model_tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcru3zBlJ3aA"
      },
      "outputs": [],
      "source": [
        "# CNN_model.load_weights(CNN_model_checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLOvHjMSIGCK"
      },
      "outputs": [],
      "source": [
        "y_pred = CNN_model.predict([X_test])\n",
        "y_pred_label = np.argmax(y_pred, axis=1)\n",
        "y_test_label = y_test\n",
        "\n",
        "class_name = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
        "print(classification_report(y_test_label, y_pred_label, target_names = class_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbx9LRV0KWHh"
      },
      "outputs": [],
      "source": [
        "LSTM_model_checkpoint_path = \"/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Saved models/LSTM/temp (1)/LSTM_model_checkpoint.ckpt\"\n",
        "LSTM_model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=LSTM_model_checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gn0nFcVD7FmC"
      },
      "outputs": [],
      "source": [
        "LSTM_model = Model(inputs=inp, outputs=out22)\n",
        "LSTM_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "batch_size = 64\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM_model.load_weights(LSTM_model_checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFMKIpmp-jCV",
        "outputId": "8eb725f9-8d47-4243-abb0-d2f28c887b94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7feec559b5d0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LSTM_hist = LSTM_model.fit(x = X_train, y = y_train, \n",
        "                 batch_size = batch_size,\n",
        "                 epochs = epochs, \n",
        "                 validation_data = (X_valid, y_valid),\n",
        "                 verbose = 1,\n",
        "                 callbacks = [LSTM_model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "YYYOPUHa-jMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4oHruEPINer"
      },
      "outputs": [],
      "source": [
        "y_pred = LSTM_model.predict([X_test])\n",
        "y_pred_label = np.argmax(y_pred, axis=1)\n",
        "y_test_label = y_test\n",
        "\n",
        "class_name = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
        "print(classification_report(y_test_label, y_pred_label, target_names = class_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN+LSTM"
      ],
      "metadata": {
        "id": "0FxuyBgZPr2h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fvRnAz47t6m"
      },
      "outputs": [],
      "source": [
        "merged = Concatenate()([out1, out2])\n",
        "\n",
        "outputs = Dense(3, activation='softmax', kernel_initializer='glorot_uniform')(merged)\n",
        "\n",
        "CNN_LSTM_merged_model = Model(inputs=inp, outputs=outputs)\n",
        "\n",
        "CNN_LSTM_merged_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "zX5-gRgjB0N7"
      },
      "outputs": [],
      "source": [
        "CNN_LSTM_merged_model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DRiQxNZNuobx"
      },
      "outputs": [],
      "source": [
        "CNN_LSTM_merged_model_checkpoint_path = \"/content/gdrive/MyDrive/COLAB_DATN/Coronavirus Tweets/Saved models/CNN_LSTM_parallel/temp/model_checkpoint.ckpt\"\n",
        "CNN_LSTM_merged_model_checkpoint_path_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=CNN_LSTM_merged_model_checkpoint_path,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eKQKZxvv0wFi"
      },
      "outputs": [],
      "source": [
        "# CNN_LSTM_merged_model.load_weights(CNN_LSTM_merged_model_checkpoint_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwXjgNX_xOYF"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "CNN_LSTM_merged_model_hist = CNN_LSTM_merged_model.fit(x = X_train, y = y_train, \n",
        "                 batch_size = batch_size,\n",
        "                 epochs = epochs, \n",
        "                 validation_data = (X_valid, y_valid),\n",
        "                 verbose = 1, \n",
        "                 callbacks = [CNN_LSTM_merged_model_checkpoint_path_checkpoint_callback])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCi-_N4hjufY"
      },
      "outputs": [],
      "source": [
        "y_pred = CNN_LSTM_merged_model.predict([X_test])\n",
        "y_pred_label = np.argmax(y_pred, axis=1)\n",
        "y_test_label = y_test\n",
        "\n",
        "class_name = [\"Negative\", \"Neutral\", \"Positive\"]\n",
        "\n",
        "print('\\t\\t\\t\\tCLASSIFICATIION METRICS\\n')\n",
        "print(classification_report(y_test_label, y_pred_label, target_names = class_name))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Google_CoronavirusTweets.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}